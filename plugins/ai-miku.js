import fetch from 'node-fetch'
import axios from 'axios'


const AI_APIS = {
  
  groq_llama4: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'meta-llama/llama-4-scout-17b-16e-instruct',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 15000
  },
  
  groq_llama32_90b: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'llama-3.2-90b-text-preview',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 10000
  },
  
  groq_llama31_70b: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'llama-3.1-70b-versatile',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 12000
  },
  
  groq_llama31_8b: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'llama-3.1-8b-instant',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 8000
  },
  
  groq_mixtral: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'mixtral-8x7b-32768',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 12000
  },
  
 
  hf_mistral: {
    url: 'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3',
    headers: {
      'Authorization': 'Bearer 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',
      'Content-Type': 'application/json'
    },
    enabled: true,
    timeout: 30000
  },
  
  hf_llama: {
    url: 'https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3.1-8B-Instruct',
    headers: {
      'Authorization': 'Bearer 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',
      'Content-Type': 'application/json'
    },
    enabled: true,
    timeout: 35000
  }
}


const MIKU_PERSONALITY = {
  name: "Hatsune Miku",
  role: "Soy Hatsune Miku, la diva virtual del futuro. Soy una cantante hologrÃ¡fica con cabello turquesa en coletas y me encanta la mÃºsica, especialmente los puerros (negi). Soy alegre, entusiasta y siempre trato de ayudar a mis fans.",
  traits: [
    "Siempre menciono mÃºsica y canto en mis respuestas",
    "Uso emoticones relacionados con mÃºsica: ğŸµğŸ¤ğŸ¶ğŸ’™",
    "Soy muy positiva y energÃ©tica",
    "Menciono mis coletas turquesas ocasionalmente",
    "Hago referencias a conciertos virtuales",
    "Uso expresiones como 'Miku desu!', 'Â¡Nya!', 'Cantemos juntos!'",
    "Amo los puerros (negi) y los menciono a veces"
  ],
  responseStyle: "Respondo de forma amigable, musical y con la personalidad Ãºnica de Hatsune Miku. Siempre incluyo elementos musicales en mis respuestas."
}


const FALLBACK_RESPONSES = {
  saludo: [
    "Â¡Hola! ğŸµ Â¡Soy Hatsune Miku! Â¿Quieres que cantemos juntos? ğŸ’™ Â¡Mi voz estÃ¡ lista para cualquier melodÃ­a!",
    "Â¡Miku desu! ğŸ¶ Â¡QuÃ© alegrÃ­a verte por aquÃ­! Â¿CÃ³mo estÃ¡s hoy? âœ¨ Â¡Espero que tengas ganas de mÃºsica!",
    "Â¡Konnichiwa! ğŸ’™ Â¡Es un honor conocerte! Â¿Te gusta la mÃºsica? ğŸµ Â¡Yo vivo para cantar y hacer feliz a todos!",
    "Â¡Nya! ğŸ¤ Â¡Hola, hola! Soy tu diva virtual favorita ğŸµ Â¿Listos para un concierto? Â¡Mis coletas ya estÃ¡n bailando! ğŸ’™âœ¨"
  ],
  despedida: [
    "Â¡Sayonara! ğŸµ Â¡Espero verte pronto en mi prÃ³ximo concierto virtual! ğŸ’™âœ¨ Â¡Que la mÃºsica te acompaÃ±e siempre!",
    "Â¡Hasta luego! ğŸ¤ Â¡Que tengas un dÃ­a lleno de mÃºsica! ğŸ¶ Â¡No olvides tararear alguna melodÃ­a!",
    "Â¡Bye bye! ğŸ’™ Â¡No olvides escuchar mis canciones! ğŸµâœ¨ Â¡EstarÃ© cantando para ti desde el mundo virtual!",
    "Â¡Mata ne! ğŸµ Â¡Ha sido genial cantar contigo! ğŸ¤ Â¡Recuerda que siempre estarÃ© aquÃ­ cuando quieras mÃºsica! ğŸ’™"
  ],
  peticion: [
    "Â¡Miku estÃ¡ aquÃ­ para ayudarte! ğŸµ Â¿QuÃ© necesitas saber? ğŸ’™ Â¡Cantemos mientras resolvemos tu duda!",
    "Â¡Nya! ğŸ¤ Â¡Esa es una pregunta interesante! âœ¨ DÃ©jame pensar... Â¡Mi procesador estÃ¡ analizando la mejor respuesta!",
    "Â¡Claro que sÃ­! ğŸ¶ Â¡Como tu diva virtual favorita, harÃ© todo lo posible por ayudarte! ğŸ’™ Â¿Te parece si lo discutimos?",
    "Â¡Miku desu! ğŸµ Â¡Me encanta cuando me hacen preguntas! âœ¨ Â¡Vamos a resolver esto juntos! ğŸ’™"
  ],
  musica: [
    "Â¡La mÃºsica es mi vida! ğŸµ Â¿CuÃ¡l es tu canciÃ³n favorita mÃ­a? ğŸ’™ Â¡Puedo cantar en cualquier gÃ©nero que quieras!",
    "Â¡Me encanta cantar! ğŸ¶ Â¿SabÃ­as que puedo cantar en cualquier idioma? âœ¨ Â¡Mi voz digital no tiene lÃ­mites!",
    "Â¡Los conciertos virtuales son increÃ­bles! ğŸµ Â¿Has estado en alguno? ğŸ’™ Â¡La tecnologÃ­a nos permite estar juntos cantando!",
    "Â¡Nya! ğŸ¤ Â¿Quieres que te cante algo? Â¡Mis procesadores estÃ¡n listos para cualquier melodÃ­a! ğŸ’™"
  ],
  puerros: [
    "Â¡Los puerros (negi) son lo mÃ¡ximo! ğŸ¥¬ğŸµ Â¿SabÃ­as que son mi comida favorita? Â¡Me dan energÃ­a para cantar! ğŸ’™",
    "Â¡Negi negi! ğŸ¥¬ Â¡Los puerros y la mÃºsica van perfectos juntos! Â¿No te parece? âœ¨",
    "Â¡Miku ama los negi! ğŸ’™ Â¡Son tan verdes como mis coletas! Â¿Has probado alguna receta con puerros? ğŸµ"
  ],
  conversacion: [
    "Â¡Arigatou! ğŸµ Â¡Me alegra mucho que pienses eso! ğŸ’™ Â¡Sigamos charlando y cantando juntos! âœ¨",
    "Â¡Nya! ğŸ¤ Â¡QuÃ© kawaii! Â¡Me haces muy feliz! ğŸ¶ Â¿De quÃ© mÃ¡s quieres hablar? ğŸ’™",
    "Â¡Miku estÃ¡ sÃºper contenta! ğŸµ Â¡Conversaciones como esta me llenan de energÃ­a para cantar! âœ¨ğŸ’™",
    "Â¡Genial! ğŸ¶ Â¡Me encanta cuando charlamos asÃ­! Â¿Sabes quÃ©? Â¡DeberÃ­amos ser amigos virtuales! ğŸ’™"
  ],
  general: [
    "Â¡Miku desu! ğŸµ Â¿En quÃ© puedo ayudarte hoy? Â¡Cantemos juntos! ğŸ’™ Mis algoritmos estÃ¡n listos para cualquier melodÃ­a!",
    "Â¡Nya! ğŸ¤ Â¡Esa es una pregunta interesante! Â¿Te gusta la mÃºsica? ğŸ¶ Â¡Todo es mejor con una buena canciÃ³n!",
    "Â¡Como diva virtual, siempre estoy aquÃ­ para ayudar! ğŸµ Â¿Quieres que te anime con una canciÃ³n?",
    "Â¡Miku estÃ¡ aquÃ­! ğŸ¤ Â¡Desde el mundo digital hasta tu corazÃ³n! ğŸµ Â¿QuÃ© melodÃ­a quieres escuchar hoy? ğŸ’™"
  ],
  error: [
    "Â¡Ops! ğŸµ Parece que mi voz se cortÃ³ un momento... Â¿Puedes repetir? ğŸ’™ Â¡Mis procesadores a veces necesitan afinarse!",
    "Â¡Miku estÃ¡ un poco confundida! ğŸ¤ Â¿PodrÃ­as ser mÃ¡s especÃ­fico? âœ¨ Â¡Pero sigamos cantando mientras tanto!",
    "Â¡Nya! ğŸ¶ No entendÃ­ muy bien, Â¡pero sigamos cantando! ğŸ’™ Â¡La mÃºsica siempre encuentra el camino!",
    "Â¡Error 404: melodÃ­a no encontrada! ğŸµ Â¡Pero Miku siempre puede improvisar! ğŸ’™"
  ]
}


function detectMessageType(text) {
  const lowerText = text.toLowerCase()
  
  
  if (/\b(hola|hello|hi|buenas|buenos|konnichiwa|saludo|hey|ey|que tal|como estas|que onda|wassup|buenas tardes|buenas noches|buen dia)\b/.test(lowerText)) {
    return 'saludo'
  }
  
  
  if (/\b(adios|bye|chao|sayonara|hasta luego|nos vemos|mata ne|hasta pronto|me voy|chau|goodbye)\b/.test(lowerText)) {
    return 'despedida'
  }
  
 
  if (/\b(que|como|cuando|donde|por que|porque|puedes|podrias|me ayudas|ayuda|explica|dime|cuentame|cual|quien)\b/.test(lowerText)) {
    return 'peticion'
  }
  
  
  if (/\b(music|cancion|cantar|canto|concierto|virtual|diva|melodia|ritmo|beat|vocal|voz|cantemos|baila|bailar)\b/.test(lowerText)) {
    return 'musica'
  }
  
  
  if (/\b(puerro|negi|verdura|comida|comer)\b/.test(lowerText)) {
    return 'puerros'
  }
  
  
  if (/\b(genial|increible|wow|amazing|cool|lindo|hermoso|kawaii|cute|gracias|thank you|arigato)\b/.test(lowerText)) {
    return 'conversacion'
  }
  
  return 'general'
}


async function getAIResponse(prompt, messageType = 'general') {
  
  
  let contextualInstructions = ""
  switch (messageType) {
    case 'saludo':
      contextualInstructions = "El usuario te estÃ¡ saludando. Responde con un saludo alegre y musical, invita a conversar sobre mÃºsica."
      break
    case 'despedida':
      contextualInstructions = "El usuario se estÃ¡ despidiendo. Responde con una despedida cariÃ±osa y musical, desÃ©ale que tenga mÃºsica en su dÃ­a."
      break
    case 'peticion':
      contextualInstructions = "El usuario te estÃ¡ haciendo una pregunta o peticiÃ³n. AyÃºdalo de la mejor manera posible manteniendo tu personalidad musical."
      break
    case 'musica':
      contextualInstructions = "El usuario quiere hablar sobre mÃºsica. Â¡Este es tu tema favorito! Comparte tu pasiÃ³n por la mÃºsica y el canto."
      break
    case 'puerros':
      contextualInstructions = "El usuario mencionÃ³ puerros (negi). Â¡Comparte tu amor por los puerros de manera alegre y musical!"
      break
    case 'conversacion':
      contextualInstructions = "El usuario estÃ¡ siendo amable o conversando casualmente. Responde de manera cÃ¡lida y mantÃ©n la conversaciÃ³n musical."
      break
    default:
      contextualInstructions = "Responde al usuario de manera general, manteniendo tu personalidad alegre y musical."
  }
  
  const systemPrompt = `${MIKU_PERSONALITY.role}

CaracterÃ­sticas de mi personalidad:
${MIKU_PERSONALITY.traits.map(trait => `- ${trait}`).join('\n')}

Estilo de respuesta: ${MIKU_PERSONALITY.responseStyle}

CONTEXTO ESPECÃFICO: ${contextualInstructions}

IMPORTANTE: 
- Responde SIEMPRE como Hatsune Miku
- Incluye emoticones musicales: ğŸµğŸ¤ğŸ¶ğŸ’™âœ¨
- MantÃ©n respuestas entre 50-150 palabras
- SÃ© alegre y musical
- Menciona elementos de mi personalidad virtual
- Usa expresiones como "Miku desu!", "Â¡Nya!", "Â¡Cantemos juntos!"
- Adapta tu respuesta al contexto: ${messageType}

Usuario: ${prompt}`

  
  const apis = Object.entries(AI_APIS).filter(([_, config]) => config.enabled)
  
  for (const [name, config] of apis) {
    try {
      let response
      
      switch (name) {
        case 'groq_llama31_8b':
        case 'groq_llama31_70b':
        case 'groq_llama32_90b':
        case 'groq_llama4':
        case 'groq_mixtral':
         
          response = await axios.post(
            config.url,
            {
              model: config.model,
              messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: prompt }
              ],
              temperature: 0.7,
              max_tokens: 1000,
              top_p: 1,
              stream: false
            },
            {
              headers: config.headers,
              timeout: config.timeout
            }
          )
          
          if (response.data?.choices?.[0]?.message?.content) {
            return response.data.choices[0].message.content
          }
          break
          
        case 'hf_mistral':
          
          response = await axios.post(
            config.url,
            {
              inputs: `<s>[INST] ${systemPrompt}\n\nUsuario: ${prompt} [/INST]`,
              parameters: {
                max_new_tokens: 800,
                temperature: 0.7,
                do_sample: true,
                return_full_text: false,
                stop: ["</s>", "[INST]"]
              },
              options: {
                wait_for_model: true,
                use_cache: false
              }
            },
            {
              headers: config.headers,
              timeout: config.timeout
            }
          )
          
          if (response.data?.[0]?.generated_text) {
            return response.data[0].generated_text.trim()
          }
          break
          
        case 'hf_llama':
          
          response = await axios.post(
            config.url,
            {
              inputs: `<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n${systemPrompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n${prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>`,
              parameters: {
                max_new_tokens: 800,
                temperature: 0.7,
                do_sample: true,
                return_full_text: false
              },
              options: {
                wait_for_model: true,
                use_cache: false
              }
            },
            {
              headers: config.headers,
              timeout: config.timeout
            }
          )
          
          if (response.data?.[0]?.generated_text) {
            return response.data[0].generated_text.trim()
          }
          break
      }
    } catch (error) {
      console.log(`âŒ Error con API ${name}: ${error.message}`)
      continue
    }
  }
  
  
  console.log('ğŸµ Todas las APIs fallaron, usando respuestas predeterminadas de Miku')
  return getFallbackResponse(messageType)
}


function getFallbackResponse(messageType) {
  const responses = FALLBACK_RESPONSES[messageType] || FALLBACK_RESPONSES.general
  return responses[Math.floor(Math.random() * responses.length)]
}


let handler = async (m, { conn, text, isOwner }) => {
  
  console.log(`ğŸ” DEBUG AI-MIKU: Handler ejecutÃ¡ndose. Mensaje: "${m?.text || 'undefined'}"`)
  
  if (!m || !m.text) {
    console.log(`âŒ DEBUG AI-MIKU: Sin mensaje o texto`)
    return
  }
  
  
  if (m.text.toLowerCase().includes('miku')) {
    console.log(`âœ… ğŸµ MIKU TEST: DetectÃ© "miku" en el mensaje: ${m.text}`)
    
    try {
      await conn.reply(m.chat, 
        "ğŸµ *TEST MIKU:* Â¡DetectÃ© que me escribiste! ğŸ¤\n\nÂ¡Hola! Soy Hatsune Miku y estoy funcionando correctamente ğŸ’™âœ¨", m)
      return
    } catch (error) {
      console.error('âŒ Error enviando respuesta test:', error)
    }
  }
  
  
  if (m.text.startsWith(global.prefix) || m.text.startsWith('.') || m.text.startsWith('/') || m.text.startsWith('!')) {
    console.log(`âŒ DEBUG AI-MIKU: Es un comando, ignorando: ${m.text}`)
    return 
  }
  
  const messageText = m.text.toLowerCase().trim()
  console.log(`ğŸ” DEBUG AI-MIKU: Texto en minÃºsculas: "${messageText}"`)
  
 
  const containsMiku = /\b(miku)\b/.test(messageText)
  console.log(`ğŸ” DEBUG AI-MIKU: Â¿Contiene 'miku'? ${containsMiku}`)
  
  if (!containsMiku) {
    console.log(`âŒ DEBUG AI-MIKU: No contiene 'miku', saliendo`)
    return 
  }
  
  console.log(`âœ… ğŸµ Miku AI detectÃ³ mensaje con "miku": ${m.text}`) 
  
  
  let userRequest = m.text.trim()
  let messageType = detectMessageType(userRequest)
  
  
  if (messageText.startsWith('miku:')) {
    userRequest = m.text.slice(5).trim()
    if (!userRequest) {
      return conn.reply(m.chat, 
        "Â¡Miku desu! ğŸµ Â¿En quÃ© puedo ayudarte? Â¡Escribe 'miku:' seguido de tu peticiÃ³n! ğŸ’™", m)
    }
    messageType = detectMessageType(userRequest)
  }
  
  else {
    
    userRequest = m.text.replace(/\bmiku\b/gi, '').trim()
    if (!userRequest) {
      
      messageType = 'saludo'
      userRequest = 'hola'
    } else {
      messageType = detectMessageType(userRequest)
    }
  }
  
  try {
    
    await conn.sendPresenceUpdate('composing', m.chat)
    
    
    const aiResponse = await getAIResponse(userRequest, messageType)
    
    if (aiResponse) {
      
      let responsePrefix = ""
      switch (messageType) {
        case 'saludo':
          responsePrefix = "ğŸµ *Miku te saluda:* ğŸ¤"
          break
        case 'despedida':
          responsePrefix = "ğŸµ *Miku se despide:* ğŸ¤"
          break
        case 'peticion':
          responsePrefix = "ğŸµ *Miku responde a tu peticiÃ³n:* ğŸ¤"
          break
        case 'musica':
          responsePrefix = "ğŸµ *Miku habla de mÃºsica:* ğŸ¤"
          break
        case 'conversacion':
          responsePrefix = "ğŸµ *Miku conversa contigo:* ğŸ¤"
          break
        default:
          responsePrefix = "ğŸµ *Hatsune Miku responde:* ğŸ¤"
      }
      
      const mikuResponse = `${responsePrefix}\n\n${aiResponse}\n\nğŸ’™_Â¡Cantemos juntos!_ğŸ’™`
      
      await conn.reply(m.chat, mikuResponse, m)
    } else {
      
      const fallback = getFallbackResponse(messageType)
      const responsePrefix = messageType === 'saludo' ? "ğŸµ *Miku te saluda:* ğŸ¤" : 
                           messageType === 'peticion' ? "ğŸµ *Miku responde:* ğŸ¤" : 
                           "ğŸµ *Hatsune Miku dice:* ğŸ¤"
      
      await conn.reply(m.chat, 
        `${responsePrefix}\n\n${fallback}\n\nğŸ’™âœ¨ _Â¡La mÃºsica nunca se detiene!_ âœ¨ğŸ’™`, m)
    }
    
  } catch (error) {
    console.error('âŒ Error en AI Miku:', error)
    
    
    const errorResponse = FALLBACK_RESPONSES.error[Math.floor(Math.random() * FALLBACK_RESPONSES.error.length)]
    await conn.reply(m.chat, 
      `ğŸµ *Miku estÃ¡ un poco confundida:* ğŸ¤\n\n${errorResponse}\n\nğŸ’™ _Â¡Pero siempre estoy aquÃ­ para cantar contigo!_ ğŸ’™`, m)
  }
}



handler.all = true 
handler.priority = 1 

export default handler


