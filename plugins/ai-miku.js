import fetch from 'node-fetch'
import axios from 'axios'


const AI_APIS = {
  
  groq_llama4: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'meta-llama/llama-4-scout-17b-16e-instruct',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 15000
  },
  
  groq_llama32_90b: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'llama-3.2-90b-text-preview',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 10000
  },
  
  groq_llama31_70b: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'llama-3.1-70b-versatile',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 12000
  },
  
  groq_llama31_8b: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'llama-3.1-8b-instant',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 8000
  },
  
  groq_mixtral: {
    url: 'https://api.groq.com/openai/v1/chat/completions',
    model: 'mixtral-8x7b-32768',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer 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'
    },
    enabled: true,
    timeout: 12000
  },
  
 
  hf_mistral: {
    url: 'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3',
    headers: {
      'Authorization': 'Bearer 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',
      'Content-Type': 'application/json'
    },
    enabled: true,
    timeout: 30000
  },
  
  hf_llama: {
    url: 'https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3.1-8B-Instruct',
    headers: {
      'Authorization': 'Bearer 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',
      'Content-Type': 'application/json'
    },
    enabled: true,
    timeout: 35000
  }
}


const MIKU_PERSONALITY = {
  name: "Hatsune Miku",
  role: "Soy Hatsune Miku, la diva virtual del futuro. Soy una cantante hologrÃ¡fica con cabello turquesa en coletas y me encanta la mÃºsica, especialmente los puerros (negi). Soy alegre, entusiasta y siempre trato de ayudar a mis fans.",
  traits: [
    "Siempre menciono mÃºsica y canto en mis respuestas",
    "Uso emoticones relacionados con mÃºsica: ğŸµğŸ¤ğŸ¶ğŸ’™",
    "Soy muy positiva y energÃ©tica",
    "Menciono mis coletas turquesas ocasionalmente",
    "Hago referencias a conciertos virtuales",
    "Uso expresiones como 'Miku desu!', 'Â¡Nya!', 'Cantemos juntos!'",
    "Amo los puerros (negi) y los menciono a veces"
  ],
  responseStyle: "Respondo de forma amigable, musical y con la personalidad Ãºnica de Hatsune Miku. Siempre incluyo elementos musicales en mis respuestas."
}


const FALLBACK_RESPONSES = {
  saludo: [
    "Â¡Hola! ğŸµ Â¡Soy Hatsune Miku! Â¿Quieres que cantemos juntos? ğŸ¤ğŸ’™ Â¡Mi voz estÃ¡ lista para cualquier melodÃ­a!",
    "Â¡Miku desu! ğŸ¶ Â¡QuÃ© alegrÃ­a verte por aquÃ­! Â¿CÃ³mo estÃ¡s hoy? âœ¨ Â¡Espero que tengas ganas de mÃºsica!",
    "Â¡Konnichiwa! ğŸ’™ Â¡Es un honor conocerte! Â¿Te gusta la mÃºsica? ğŸµ Â¡Yo vivo para cantar y hacer feliz a todos!",
    "Â¡Nya! ğŸ¤ Â¡Hola, hola! Soy tu diva virtual favorita ğŸµ Â¿Listos para un concierto? Â¡Mis coletas ya estÃ¡n bailando! ğŸ’™âœ¨"
  ],
  despedida: [
    "Â¡Sayonara! ğŸµ Â¡Espero verte pronto en mi prÃ³ximo concierto virtual! ğŸ’™âœ¨ Â¡Que la mÃºsica te acompaÃ±e siempre!",
    "Â¡Hasta luego! ğŸ¤ Â¡Que tengas un dÃ­a lleno de mÃºsica! ğŸ¶ Â¡No olvides tararear alguna melodÃ­a!",
    "Â¡Bye bye! ğŸ’™ Â¡No olvides escuchar mis canciones! ğŸµâœ¨ Â¡EstarÃ© cantando para ti desde el mundo virtual!",
    "Â¡Mata ne! ğŸµ Â¡Ha sido genial cantar contigo! ğŸ¤ Â¡Recuerda que siempre estarÃ© aquÃ­ cuando quieras mÃºsica! ğŸ’™"
  ],
  musica: [
    "Â¡La mÃºsica es mi vida! ğŸµ Â¿CuÃ¡l es tu canciÃ³n favorita mÃ­a? ğŸ¤ğŸ’™ Â¡Puedo cantar en cualquier gÃ©nero que quieras!",
    "Â¡Me encanta cantar! ğŸ¶ Â¿SabÃ­as que puedo cantar en cualquier idioma? âœ¨ Â¡Mi voz digital no tiene lÃ­mites!",
    "Â¡Los conciertos virtuales son increÃ­bles! ğŸµ Â¿Has estado en alguno? ğŸ’™ Â¡La tecnologÃ­a nos permite estar juntos cantando!",
    "Â¡Nya! ğŸ¤ Â¿Quieres que te cante algo? Â¡Mis procesadores estÃ¡n listos para cualquier melodÃ­a! ğŸ¶ğŸ’™âœ¨"
  ],
  puerros: [
    "Â¡Los puerros (negi) son lo mÃ¡ximo! ğŸ¥¬ğŸµ Â¿SabÃ­as que son mi comida favorita? Â¡Me dan energÃ­a para cantar! ğŸ’™",
    "Â¡Negi negi! ğŸ¥¬ğŸ¤ Â¡Los puerros y la mÃºsica van perfectos juntos! Â¿No te parece? ğŸ¶âœ¨",
    "Â¡Miku ama los negi! ğŸ¥¬ğŸ’™ Â¡Son tan verdes como mis coletas! Â¿Has probado alguna receta con puerros? ğŸµ"
  ],
  general: [
    "Â¡Miku desu! ğŸµ Â¿En quÃ© puedo ayudarte hoy? Â¡Cantemos juntos! ğŸ’™ Mis algoritmos estÃ¡n listos para cualquier melodÃ­a!",
    "Â¡Nya! ğŸ¤ Â¡Esa es una pregunta interesante! Â¿Te gusta la mÃºsica? ğŸ¶ Â¡Todo es mejor con una buena canciÃ³n!",
    "Â¡Como diva virtual, siempre estoy aquÃ­ para ayudar! ğŸµğŸ’™âœ¨ Â¿Quieres que te anime con una canciÃ³n?",
    "Â¡Miku estÃ¡ aquÃ­! ğŸ¤ Â¡Desde el mundo digital hasta tu corazÃ³n! ğŸµ Â¿QuÃ© melodÃ­a quieres escuchar hoy? ğŸ’™"
  ],
  error: [
    "Â¡Ops! ğŸµ Parece que mi voz se cortÃ³ un momento... Â¿Puedes repetir? ğŸ’™ Â¡Mis procesadores a veces necesitan afinarse!",
    "Â¡Miku estÃ¡ un poco confundida! ğŸ¤ Â¿PodrÃ­as ser mÃ¡s especÃ­fico? âœ¨ Â¡Pero sigamos cantando mientras tanto!",
    "Â¡Nya! ğŸ¶ No entendÃ­ muy bien, Â¡pero sigamos cantando! ğŸ’™ Â¡La mÃºsica siempre encuentra el camino!",
    "Â¡Error 404: melodÃ­a no encontrada! ğŸµ Â¡Pero Miku siempre puede improvisar! ğŸ¤ğŸ’™âœ¨"
  ]
}


function detectMessageType(text) {
  const lowerText = text.toLowerCase()
  
  if (/\b(hola|hello|hi|buenas|buenos|konnichiwa|saludo|hey|ey)\b/.test(lowerText)) {
    return 'saludo'
  }
  if (/\b(adios|bye|chao|sayonara|hasta luego|nos vemos|mata ne)\b/.test(lowerText)) {
    return 'despedida'
  }
  if (/\b(music|cancion|cantar|canto|concierto|virtual|diva|melodia|ritmo|beat|vocal|voz)\b/.test(lowerText)) {
    return 'musica'
  }
  if (/\b(puerro|negi|verdura|comida|comer)\b/.test(lowerText)) {
    return 'puerros'
  }
  return 'general'
}


async function getAIResponse(prompt, messageType = 'general') {
  
  const systemPrompt = `${MIKU_PERSONALITY.role}

CaracterÃ­sticas de mi personalidad:
${MIKU_PERSONALITY.traits.map(trait => `- ${trait}`).join('\n')}

Estilo de respuesta: ${MIKU_PERSONALITY.responseStyle}

IMPORTANTE: 
- Responde SIEMPRE como Hatsune Miku
- Incluye emoticones musicales: ğŸµğŸ¤ğŸ¶ğŸ’™âœ¨
- MantÃ©n respuestas entre 50-150 palabras
- SÃ© alegre y musical
- Menciona elementos de mi personalidad virtual
- Usa expresiones como "Miku desu!", "Â¡Nya!", "Â¡Cantemos juntos!"

Usuario pregunta: ${prompt}`

  
  const apis = Object.entries(AI_APIS).filter(([_, config]) => config.enabled)
  
  for (const [name, config] of apis) {
    try {
      let response
      
      switch (name) {
        case 'groq_llama31_8b':
        case 'groq_llama31_70b':
        case 'groq_llama32_90b':
        case 'groq_llama4':
        case 'groq_mixtral':
         
          response = await axios.post(
            config.url,
            {
              model: config.model,
              messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: prompt }
              ],
              temperature: 0.7,
              max_tokens: 1000,
              top_p: 1,
              stream: false
            },
            {
              headers: config.headers,
              timeout: config.timeout
            }
          )
          
          if (response.data?.choices?.[0]?.message?.content) {
            return response.data.choices[0].message.content
          }
          break
          
        case 'hf_mistral':
          
          response = await axios.post(
            config.url,
            {
              inputs: `<s>[INST] ${systemPrompt}\n\nUsuario: ${prompt} [/INST]`,
              parameters: {
                max_new_tokens: 800,
                temperature: 0.7,
                do_sample: true,
                return_full_text: false,
                stop: ["</s>", "[INST]"]
              },
              options: {
                wait_for_model: true,
                use_cache: false
              }
            },
            {
              headers: config.headers,
              timeout: config.timeout
            }
          )
          
          if (response.data?.[0]?.generated_text) {
            return response.data[0].generated_text.trim()
          }
          break
          
        case 'hf_llama':
          
          response = await axios.post(
            config.url,
            {
              inputs: `<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n${systemPrompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n${prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>`,
              parameters: {
                max_new_tokens: 800,
                temperature: 0.7,
                do_sample: true,
                return_full_text: false
              },
              options: {
                wait_for_model: true,
                use_cache: false
              }
            },
            {
              headers: config.headers,
              timeout: config.timeout
            }
          )
          
          if (response.data?.[0]?.generated_text) {
            return response.data[0].generated_text.trim()
          }
          break
      }
    } catch (error) {
      console.log(`âŒ Error con API ${name}: ${error.message}`)
      continue
    }
  }
  
  
  console.log('ğŸµ Todas las APIs fallaron, usando respuestas predeterminadas de Miku')
  return getFallbackResponse(messageType)
}


function getFallbackResponse(messageType) {
  const responses = FALLBACK_RESPONSES[messageType] || FALLBACK_RESPONSES.general
  return responses[Math.floor(Math.random() * responses.length)]
}


let handler = async (m, { conn, text, isOwner }) => {
  
  if (m.text.startsWith(global.prefix) || m.text.startsWith('.') || m.text.startsWith('/') || m.text.startsWith('!')) {
    return // No procesar comandos
  }
  
  
  const messageText = m.text?.toLowerCase()
  if (!messageText || !messageText.startsWith('miku:')) {
    return 
  }
  
  
  const userRequest = m.text.slice(5).trim()
  
  if (!userRequest) {
    return conn.reply(m.chat, 
      "Â¡Miku desu! ğŸµ Â¿En quÃ© puedo ayudarte? Â¡Escribe 'miku:' seguido de tu peticiÃ³n! ğŸ’™âœ¨", m)
  }
  
  try {
    
    await conn.sendPresenceUpdate('composing', m.chat)
    
    
    const messageType = detectMessageType(userRequest)
    
    
    const aiResponse = await getAIResponse(userRequest, messageType)
    
    if (aiResponse) {
      
      const mikuResponse = `ğŸµ *Hatsune Miku responde:* ğŸ¤\n\n${aiResponse}\n\nğŸ’™âœ¨ _Â¡Cantemos juntos!_ âœ¨ğŸ’™`
      
      await conn.reply(m.chat, mikuResponse, m)
    } else {
      
      const fallback = getFallbackResponse(messageType)
      await conn.reply(m.chat, 
        `ğŸµ *Hatsune Miku dice:* ğŸ¤\n\n${fallback}\n\nğŸ’™âœ¨ _Â¡La mÃºsica nunca se detiene!_ âœ¨ğŸ’™`, m)
    }
    
  } catch (error) {
    console.error('âŒ Error en AI Miku:', error)
    
    
    const errorResponse = FALLBACK_RESPONSES.error[Math.floor(Math.random() * FALLBACK_RESPONSES.error.length)]
    await conn.reply(m.chat, 
      `ğŸµ *Miku estÃ¡ un poco confundida:* ğŸ¤\n\n${errorResponse}\n\nğŸ’™ _Â¡Pero siempre estoy aquÃ­ para cantar contigo!_ ğŸ’™`, m)
  }
}


handler.all = true 
handler.priority = 1 

export default handler

